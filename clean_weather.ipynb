from pyspark.sql import SparkSession
from pyspark.sql.functions import input_file_name
from datetime import datetime,timedelta

spark=SparkSession.builder.appName("weather_daily_cleaning").getOrCreate()
yesterday=(datetime.today()-timedelta(days=1)).strftime("%Y/%m/%d")

bucket="gs://ubike-471005-data-lake/weather_raw/"
input_path=f"{bucket}{yesterday}/*.json"

df=spark.read.json(input_path). withColumn("source_file", input_file_name()

df.show(5, truncate=False)
